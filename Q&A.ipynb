{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.write a sql query to return unique records from a table without using Distinct or GroupBy\n",
    "\n",
    "\n",
    "WITH RankedRecords AS (\n",
    "    SELECT \n",
    "        *,\n",
    "        ROW_NUMBER() OVER (PARTITION BY first_name) AS rn\n",
    "    FROM \n",
    "        Customers\n",
    ")\n",
    "SELECT \n",
    "    customer_id, first_name, last_name\n",
    "FROM \n",
    "    RankedRecords\n",
    "WHERE \n",
    "    rn = 1;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SELECT DISTINCT first_name FROM Customers;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#second highest salary\n",
    "\n",
    "SELECT name, salary  \n",
    "FROM employee  \n",
    "WHERE salary = (  \n",
    "    SELECT MAX(salary)  \n",
    "    FROM employee  \n",
    "    WHERE salary < (SELECT MAX(salary) FROM employee)  \n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.write a query to find the maximum paid amount  from a customer table?\n",
    "\n",
    "SELECT MAX(age) as highest_amount\n",
    "FROM Customers\n",
    "GROUP BY age;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Explain the difference between Left join, Right Join, Inner join in sql ?\n",
    "\n",
    "\n",
    "\n",
    "1. LEFT JOIN (or LEFT OUTER JOIN)\n",
    "\n",
    "A LEFT JOIN returns all records from the left table (Table A), and the matched records from the right table (Table B). If there is no match, the result is NULL on the side of the right table.\n",
    "\n",
    "Example:\n",
    "\n",
    "SELECT Customers.CustomerName, Orders.OrderID\n",
    "FROM Customers\n",
    "LEFT JOIN Orders ON Customers.CustomerID = Orders.CustomerID\n",
    "ORDER BY Customers.CustomerName;\n",
    "\n",
    "Result: All rows from Table A, and matched rows from Table B. Unmatched rows from Table B will have NULL values.\n",
    "2. RIGHT JOIN (or RIGHT OUTER JOIN)\n",
    "\n",
    "A RIGHT JOIN returns all records from the right table (Table B), and the matched records from the left table (Table A). If there is no match, the result is NULL on the side of the left table.\n",
    "\n",
    "Example:\n",
    "\n",
    "SELECT Orders.OrderID, Employees.LastName, Employees.FirstName\n",
    "FROM Orders\n",
    "RIGHT JOIN Employees ON Orders.EmployeeID = Employees.EmployeeID\n",
    "ORDER BY Orders.OrderID;\n",
    "\n",
    "Result: All rows from Table B, and matched rows from Table A. Unmatched rows from Table A will have NULL values.\n",
    "3. INNER JOIN\n",
    "\n",
    "An INNER JOIN returns only the records that have matching values in both tables. It excludes rows that do not have matches in both tables.\n",
    "\n",
    "Example:\n",
    "\n",
    "SELECT Orders.OrderID, Customers.CustomerName\n",
    "FROM Orders\n",
    "INNER JOIN Customers ON Orders.CustomerID = Customers.CustomerID;\n",
    "\n",
    "Result: Only rows where there is a match in both Table A and Table B.\n",
    "Summary\n",
    "LEFT JOIN: All rows from the left table, matched rows from the right table, NULL for unmatched rows from the right table.\n",
    "RIGHT JOIN: All rows from the right table, matched rows from the left table, NULL for unmatched rows from the left table.\n",
    "INNER JOIN: Only rows with matches in both tables.\n",
    "\n",
    "\n",
    "4. FULL JOIN\n",
    "\n",
    "full join or full outer join that combines all records from two tables, regardless of whether they have matching values in the specified column. if there is a match the rows are merged. if there is no match null values are used to fill.\n",
    "\n",
    "SELECT Orders.OrderID, Customers.CustomerName\n",
    "FROM Orders\n",
    "FULL OUTER JOIN Customers ON Orders.CustomerID = Customers.CustomerID;\n",
    "\n",
    "\n",
    "5. CROSS JOIN\n",
    "\n",
    "In SQL, the CROSS JOIN is a unique join operation that returns the Cartesian product of two or more tables. This means it matches each row from the left table with every row from the right table, resulting in a combination of all possible pairs of records. (3*4=12)\n",
    "\n",
    "SELECT * FROM table1\n",
    "CROSS JOIN table2;\n",
    "\n",
    "\n",
    "6. SELF JOIN\n",
    "\n",
    "A self join in SQL is a join in which a table is joined with itself. This can be useful for comparing rows within the same table.\n",
    "\n",
    "select a.first_name, b.last_name\n",
    "from customers a\n",
    "join customers b\n",
    "on a.customer_id=b.customer_id;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. How do you reverse a string in python without using slicing?\n",
    "\n",
    "\n",
    "str = \"hello\"\n",
    "res=\"\"\n",
    "\n",
    "for i in str:\n",
    "    res=i+res\n",
    "print(res)\n",
    "\n",
    "\n",
    "res=str[::-1]\n",
    "print(res)\n",
    "\n",
    "\n",
    "res=''.join(reversed(str))\n",
    "print(res)\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "\n",
    "a = ['10', '20', '4', '45', '99']\n",
    "a1 = [10, 20, 4, 45, 99]\n",
    "\n",
    "\n",
    "res=a[::-1] #or a1[::-1]\n",
    "\n",
    "res=list(reversed(a)) # or res=list(reversed(a1))\n",
    "\n",
    "a.reverse() # or a1.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "#2.how would you find the second largest number in a list without sorting it?\n",
    "\n",
    "a = [10, 20, 40, 45, 99]\n",
    "\n",
    "res=sorted(set(a))\n",
    "res[-2]\n",
    "\n",
    "\n",
    "largest = second_largest = float('-inf')\n",
    "\n",
    "for num in a:\n",
    "    if num > largest:\n",
    "        second_largest, largest = largest, num\n",
    "\n",
    "    elif num > second_largest and num != largest:\n",
    "        second_largest = num\n",
    "\n",
    "print(largest)\n",
    "print(second_largest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling missing values (fillna method)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "newdf = df.fillna(222222)\n",
    "\n",
    "print(newdf.to_string()) #Note that we use the to_string() method to return the entire DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APPLE</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banana</td>\n",
       "      <td>20</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orange</td>\n",
       "      <td>30</td>\n",
       "      <td>0.7</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Item  Quantity  Price  total\n",
       "0   APPLE        10    0.5    5.0\n",
       "1  banana        20    0.3    6.0\n",
       "2  orange        30    0.7   21.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Item': ['APPLE', 'banana', 'orange'],'Quantity': [10, 20, 30],'Price': [0.5, 0.3, 0.7]}\n",
    "df = pd.DataFrame(data)\n",
    "total=[]\n",
    "for index, row in df.iterrows():\n",
    "    total.append(row['Quantity'] * row['Price'])\n",
    "df['total'] = total\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating through each row in the dataframes & to capitalise one particular column\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Item': ['APPLE', 'banana', 'orange'],'Quantity': [10, 20, 30],'Price': [0.5, 0.3, 0.7]}\n",
    "df = pd.DataFrame(data)\n",
    "for index, row in df.iterrows():\n",
    "    total_sales = row['Quantity'] * row['Price']\n",
    "\n",
    "\n",
    "df[\"Item\"]=df[\"Item\"].apply(lambda x:x.capitalize())\n",
    "df[\"Item\"]=df[\"Item\"].str.lower()\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how code is optimised if need to handle large data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Efficient Data Structures\n",
    " \n",
    "Use Pandas wisely:\n",
    " \n",
    "Use pandas.read_csv() with options like dtype, usecols, and chunksize to control memory usage.\n",
    " \n",
    "Use DataFrame.astype() to downcast numeric columns (e.g., float64 → float32).\n",
    " \n",
    " \n",
    "Numpy Arrays: Use NumPy arrays for numeric computations instead of Python lists.\n",
    " \n",
    "Generators: Use generators instead of lists for iterating through large datasets to avoid loading everything into memory at once.\n",
    " \n",
    " \n",
    " \n",
    "---\n",
    " \n",
    "2. Chunking and Parallel Processing\n",
    " \n",
    "Chunk Loading: Read and process the dataset in chunks (e.g., using pandas.read_csv(chunksize=...)) to reduce memory footprint.\n",
    " \n",
    "Parallel Processing: Use libraries like:\n",
    " \n",
    "multiprocessing for parallel execution.\n",
    " \n",
    "joblib for parallel loops.\n",
    " \n",
    "dask to parallelize Pandas operations and manage computations across multiple cores.\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "---\n",
    " \n",
    "3. Memory Management\n",
    " \n",
    "Garbage Collection: Explicitly invoke garbage collection with gc.collect() when processing large datasets.\n",
    " \n",
    "Memory Profiler: Use tools like memory_profiler or tracemalloc to identify memory bottlenecks.\n",
    " \n",
    "Delete Unused Variables: Use del to free memory for variables no longer in use.\n",
    " \n",
    " \n",
    " \n",
    "---\n",
    " \n",
    "4. Optimize File Formats\n",
    " \n",
    "Use efficient file formats such as:\n",
    " \n",
    "HDF5: pandas.HDFStore for storing large datasets efficiently.\n",
    " \n",
    "Parquet: Optimized for reading/writing tabular data with tools like pandas.read_parquet.\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "---\n",
    " \n",
    "5. Algorithmic Optimization\n",
    " \n",
    "Avoid Loops: Replace Python loops with vectorized operations in NumPy or Pandas.\n",
    " \n",
    "Efficient Sorting/Filtering: Use built-in sorting and filtering functions instead of custom logic.\n",
    " \n",
    "Sparse Matrices: Use sparse matrix representations for datasets with many zeros (e.g., scipy.sparse).\n",
    " \n",
    " \n",
    " \n",
    "---\n",
    " \n",
    "6. Streaming and Lazy Evaluation\n",
    " \n",
    "Use libraries like Dask or PySpark for streaming data and lazy evaluation, enabling operations on datasets that don't fit in memory.\n",
    " \n",
    " \n",
    " \n",
    "---\n",
    " \n",
    "7. Profiling Tools\n",
    " \n",
    "Use profiling tools to identify bottlenecks:\n",
    " \n",
    "cProfile or line_profiler: For function-level profiling.\n",
    " \n",
    "memory_profiler: For memory usage analysis.\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "---\n",
    " \n",
    "8. Database Usage\n",
    " \n",
    "For extremely large datasets, consider using databases:\n",
    " \n",
    "SQL Databases: Use SQL queries for filtering and aggregating large datasets.\n",
    " \n",
    "NoSQL Databases: For unstructured data, tools like MongoDB or Apache Cassandra can be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Parameter                                         DELETE  \\\n",
      "0              Type                                            DML   \n",
      "1           Purpose       Deletes specific rows based on condition   \n",
      "2            Syntax        DELETE FROM table_name WHERE condition;   \n",
      "3  Rollback Support                                Can be Rollback   \n",
      "4      Data Removal                          Removes selected rows   \n",
      "5        Efficiency  Slower, as each row is processed individually   \n",
      "6          Triggers                                 Fires triggers   \n",
      "\n",
      "                                   DROP  \\\n",
      "0                                   DDL   \n",
      "1  Deletes the entire table or database   \n",
      "2                DROP TABLE table_name;   \n",
      "3                    Cannot be Rollback   \n",
      "4     Removes table and data completely   \n",
      "5     Instant removal, affecting schema   \n",
      "6                Does not fire triggers   \n",
      "\n",
      "                                       TRUNCATE  \n",
      "0                                           DDL  \n",
      "1  Deletes all rows but retains table structure  \n",
      "2                    TRUNCATE TABLE table_name;  \n",
      "3                            Cannot be Rollback  \n",
      "4                              Removes all rows  \n",
      "5       Faster than DELETE but slower than DROP  \n",
      "6                        Does not fire triggers  \n"
     ]
    }
   ],
   "source": [
    "#drop vs delete vs truncate\n",
    "\n",
    "import pandas as pd\n",
    "data=pd.read_excel(r\"C:\\Users\\2012171\\Downloads\\Book1.xlsx\")\n",
    "\n",
    "pd.set_option('display.max_rows', None)  \n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.width', None) \n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace string after whitespace\n",
    "\n",
    "str=\"hello \"\n",
    "res=str.replace(\" \",\" \"+ str)\n",
    "res=str.replace(\" \",\"\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Where clause vs Alias vs Blob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alias (Aliases are used to give a table, or a column in a table, a temporary name.\n",
    "\n",
    "Aliases are often used to make column names more readable.\n",
    "\n",
    "An alias only exists for the duration of that query.\n",
    "\n",
    "An alias is created with the AS keyword)\n",
    "\n",
    "\n",
    " select first_name as name from customers;\n",
    "\n",
    "\n",
    "2. Where (The WHERE clause is used to filter records.)\n",
    "\n",
    "SELECT column1, column2, ...\n",
    "FROM table_name\n",
    "WHERE condition;\n",
    "\n",
    "\n",
    "3. A BLOB (Binary Large Object) is a data type in MySQL that allows you to store large binary data such as images, audio, video, and other multimedia files. BLOBs are useful when you need to store and retrieve binary data in your database.\n",
    "\n",
    "Types of BLOBs in MySQL\n",
    "\n",
    "MySQL supports four types of BLOBs, each with different maximum lengths:\n",
    "\n",
    "TINYBLOB: Maximum length of 255 bytes.\n",
    "\n",
    "BLOB: Maximum length of 65,535 bytes.\n",
    "\n",
    "MEDIUMBLOB: Maximum length of 16,777,215 bytes.\n",
    "\n",
    "LONGBLOB: Maximum length of 4,294,967,295 bytes\n",
    "\n",
    "\n",
    "CREATE TABLE images (\n",
    "id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "title VARCHAR(255) NOT NULL,\n",
    "image_data LONGBLOB NOT NULL\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stored procedure in MySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A stored procedure is a prepared SQL code that you can save, so the code can be reused over and over again.\n",
    "\n",
    "So if you have an SQL query that you write over and over again, save it as a stored procedure, and then just call it to execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating table in mysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE TABLE Persons (\n",
    "    PersonID int,\n",
    "    LastName varchar(255),\n",
    "    FirstName varchar(255),\n",
    "    Address varchar(255),\n",
    "    City varchar(255)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuple vs List vs Set in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists\n",
    "\n",
    "Lists are ordered collections of items that are mutable, meaning you can change their content by adding, removing, or modifying elements. Lists can contain duplicate elements and are defined using square brackets [].\n",
    "\n",
    "Example:\n",
    "\n",
    "# Creating a list\n",
    "my_list = [1, 2, 3, 4, 5]\n",
    "print(my_list) # Output: [1, 2, 3, 4, 5]\n",
    "\n",
    "# Modifying a list\n",
    "my_list.append(6)\n",
    "print(my_list) # Output: [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "my_list[0] = 0\n",
    "print(my_list) # Output: [0, 2, 3, 4, 5, 6]\n",
    "Lists are ideal for scenarios where you need an ordered collection of items that may change over time\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------\n",
    "Tuples\n",
    "\n",
    "Tuples are similar to lists but are immutable, meaning once they are created, their content cannot be changed. Tuples can contain duplicate elements and are defined using parentheses ().\n",
    "\n",
    "Example:\n",
    "\n",
    "# Creating a tuple\n",
    "my_tuple = (1, 2, 3, 4, 5)\n",
    "print(my_tuple) # Output: (1, 2, 3, 4, 5)\n",
    "\n",
    "# Accessing elements in a tuple\n",
    "print(my_tuple[0]) # Output: 1\n",
    "Tuples are useful for storing fixed collections of items, such as coordinates or configuration settings\n",
    "\n",
    "\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------------------------\n",
    "Sets\n",
    "\n",
    "Sets are unordered collections of unique elements. They are mutable, meaning you can add or remove elements, but they do not allow duplicate elements. Sets are defined using curly braces {}.\n",
    "\n",
    "Example:\n",
    "\n",
    "# Creating a set\n",
    "my_set = {1, 2, 3, 4, 5}\n",
    "print(my_set) # Output: {1, 2, 3, 4, 5}\n",
    "\n",
    "# Modifying a set\n",
    "my_set.add(6)\n",
    "print(my_set) # Output: {1, 2, 3, 4, 5, 6}\n",
    "\n",
    "my_set.remove(1)\n",
    "print(my_set) # Output: {2, 3, 4, 5, 6}\n",
    "Sets are ideal for scenarios where you need to store unique elements and perform operations like union, intersection, and difference\n",
    "\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "Key Differences\n",
    "\n",
    "Mutability: Lists and sets are mutable, while tuples are immutable.\n",
    "\n",
    "Order: Lists and tuples maintain the order of elements, while sets do not.\n",
    "\n",
    "Duplicates: Lists and tuples allow duplicate elements, while sets do not\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging data frame values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  First Name Last Name   Full Name\n",
      "0       John       Doe    John Doe\n",
      "1       Jane     Smith  Jane Smith\n",
      "   A  B\n",
      "0  1  3\n",
      "1  2  4\n",
      "0  5  7\n",
      "1  6  8\n",
      "   ID  Name  Age\n",
      "0   1  John   28\n",
      "1   2  Jane   34\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    " \n",
    "df = pd.DataFrame({'First Name': ['John', 'Jane'], 'Last Name': ['Doe', 'Smith']})\n",
    "df['Full Name'] = df['First Name'] + ' ' + df['Last Name']  \n",
    "print(df)\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n",
    "merged_df = pd.concat([df1, df2])\n",
    "print(merged_df)\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame({'ID': [1, 2], 'Name': ['John', 'Jane']})\n",
    "df2 = pd.DataFrame({'ID': [1, 2], 'Age': [28, 34]})\n",
    "merged_df = pd.merge(df1, df2, on='ID')\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#types of error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SyntaxError\n",
    "Invalid Python code\n",
    "\n",
    "IndentationError\n",
    "Incorrect code structure\n",
    "\n",
    "TypeError\n",
    "Incompatible data types\n",
    "\n",
    "AttributeError\n",
    "Non-existent object attribute\n",
    "\n",
    "ImportError\n",
    "Missing or inaccessible module\n",
    "\n",
    "ValueError\n",
    "Inappropriate function value\n",
    "\n",
    "IOError\n",
    "Failed input/output operation\n",
    "\n",
    "NameError\n",
    "Undefined variable or function\n",
    "\n",
    "IndexError\n",
    "Out of range list index\n",
    "\n",
    "KeyError\n",
    "Non-existent dictionary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep Copy vs Shallow Copy in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shallow Copy\n",
    "\n",
    "A shallow copy creates a new object, but it does not create copies of nested objects. Instead, it copies references to the nested objects. This means that changes to nested objects in the copied object will affect the original object and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original List: [[1, 2, 3], [4, 'AA', 6], [7, 8, 9]]\n",
      "Shallow Copied List: [[1, 2, 3], [4, 'AA', 6], [7, 8, 9]]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "original_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "shallow_copied_list = copy.copy(original_list)\n",
    "\n",
    "# Modifying the nested object in the original list\n",
    "original_list[1][1] = 'AA'\n",
    "\n",
    "print(\"Original List:\", original_list)\n",
    "print(\"Shallow Copied List:\", shallow_copied_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Copy\n",
    "\n",
    "A deep copy creates a new object and recursively copies all nested objects. This means that the original and copied objects are completely independent, and changes to one do not affect the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "original_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "deep_copied_list = copy.deepcopy(original_list)\n",
    "\n",
    "# Modifying the nested object in the original list\n",
    "original_list[1][1] = 'BB'\n",
    "\n",
    "print(\"Original List:\", original_list)\n",
    "print(\"Deep Copied List:\", deep_copied_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#memory management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, memory management involves two primary areas: heap memory and stack memory. Here's a breakdown of the differences:\n",
    " \n",
    "1. Stack Memory:\n",
    " \n",
    "Usage: The stack is used for static memory allocation, such as function calls and local variables.\n",
    " \n",
    "Storage: It stores references to objects and local variables. When a function is called, its local variables are stored on the stack, and they are removed once the function returns.\n",
    " \n",
    "Size: Stack memory is generally limited in size, and attempting to use too much stack space (e.g., with deep recursion) can lead to a stack overflow.\n",
    " \n",
    "Lifetime: The lifetime of stack variables is tied to the scope in which they are created. They are automatically destroyed when the function scope ends.\n",
    " \n",
    " \n",
    "2. Heap Memory:\n",
    " \n",
    "Usage: The heap is used for dynamic memory allocation. Objects like lists, dictionaries, and user-defined objects (class instances) are stored here.\n",
    " \n",
    "Storage: The heap stores objects that need to persist beyond the scope of the function that created them (i.e., globally or across function calls).\n",
    " \n",
    "Size: The heap is much larger compared to the stack, and memory is allocated dynamically. It is managed by the Python runtime (specifically, the garbage collector).\n",
    " \n",
    "Lifetime: The lifetime of objects in the heap is managed through reference counting and garbage collection. An object is only removed from the heap when there are no more references to it.\n",
    " \n",
    " \n",
    "Key Differences:\n",
    " \n",
    "In Python, objects (such as lists, dictionaries, and class instances) are stored in the heap, and variables that reference them are stored in the stack. For example:\n",
    " \n",
    "def my_function():\n",
    "    a = [1, 2, 3]  # 'a' is on the stack, list [1, 2, 3] is on the heap\n",
    "    print(a)\n",
    " \n",
    "my_function()\n",
    " \n",
    "Here, the list [1, 2, 3] is stored in the heap, while the variable a is stored in the stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#altering dictionary, merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {'x': 1, 'y': 2}\n",
    "d2 = {'y': 3, 'z': 4}\n",
    "\n",
    "d1.update(d2)\n",
    "print(d1)\n",
    "\n",
    "\n",
    "d1 = {'x': 1, 'y': 2}\n",
    "d2 = {'y': 3, 'z': 4}\n",
    "d3 = {**d1, **d2}\n",
    "print(d3)\n",
    "\n",
    "\n",
    "d1 = {'x': 1, 'y': 2}\n",
    "d2 = {'y': 3, 'z': 4}\n",
    "d3 = d1.copy()\n",
    "for key,value in d2.items():\n",
    "    d3[key] = value\n",
    "print(d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how exceptions are handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "division by zero\n",
      "finally\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # print(\"try\")\n",
    "    res=0/0\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"else\")\n",
    "finally:\n",
    "    print(\"finally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 20, 30, 40, 50]\n",
      "[10, 20, 30, 40, 50]\n"
     ]
    }
   ],
   "source": [
    "listt=[10,20,30,30,40,50,50]\n",
    "temp=[]\n",
    "for item in listt:\n",
    "    if item not in temp:\n",
    "        temp.append(item)\n",
    "print(temp)\n",
    "\n",
    "temp=sorted(set(listt))\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accessing dataframe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7058\n",
      "sravan\n",
      "java\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    \"id\": [7058, 7059, 7072, 7054],\n",
    "    \"name\": ['sravan', 'jyothika', 'harsha', 'ramya'],\n",
    "    \"subjects\": ['java', 'python', 'html/php', 'php/js']\n",
    "})\n",
    "\n",
    "print(data[\"id\"].iloc[0])\n",
    "print(data[\"name\"].values[0])\n",
    "print(data[\"subjects\"].loc[data.index[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string operations, indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str=\" hello hello \"\n",
    "res=str.casefold()\n",
    "res=str.lower()\n",
    "res=str.upper()\n",
    "res=str.count(\"hello\")#2\n",
    "res=str.endswith('h')#True\n",
    "res=' '.join(str)#h e l l o   h e l l o\n",
    "res=str.lstrip()#remove left side space\n",
    "res=str.rstrip()#remove right side space\n",
    "res=str.replace('h','l')\n",
    "res=str.rfind(\"hello\")#6th position from starting\n",
    "res=str.split()#['hello', 'hello']\n",
    "res=str.strip()#remove entire space in the string\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#predict the o/p\n",
    "\n",
    "def fun():\n",
    "    print(\"hello\")\n",
    "a=fun()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[122], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m a\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      2\u001b[0m b\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m c\u001b[38;5;241m=\u001b[39m\u001b[43ma\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mb\u001b[49m\n\u001b[0;32m      4\u001b[0m c\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "#predict the o/p\n",
    "\n",
    "a=10\n",
    "b=\"hello\"\n",
    "c=a+b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate window function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Aggregate Window Functions include:\n",
    "\n",
    "SUM()\n",
    "AVG()\n",
    "COUNT()\n",
    "MAX()\n",
    "MIN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common Table Expression (CTE) vs Sub-Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SQL, a Common Table Expression (CTE) is an essential tool for simplifying complex queries and making them more readable. By defining temporary result sets that can be referenced multiple times, a CTE in SQL allows developers to break down complicated logic into manageable parts. A Common Table Expression (CTE) in SQL is a temporary result set that is defined and used within the execution scope of a SELECT, INSERT, UPDATE, or DELETE statement.\n",
    "\n",
    "\n",
    "WITH cte_name AS (\n",
    "    SELECT query\n",
    ")\n",
    "SELECT *\n",
    "FROM cte_name;\n",
    "\n",
    "\n",
    "cte_name: A unique name for the CTE expression.\n",
    "query: A valid SQL query that returns a result set, which will be treated as a virtual table within the main query.\n",
    "SELECT: The main query that can reference the CTE by its name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SQL, a subquery can be defined as a query embedded within another query. It is often used in the WHERE, HAVING, or FROM clauses of a statement. Subqueries are commonly used with SELECT, UPDATE, INSERT, and DELETE statements to achieve complex filtering and data manipulation.\n",
    "\n",
    "SELECT NAME, LOCATION, PHONE_NUMBER \n",
    "FROM DATABASE \n",
    "WHERE ROLL_NO IN (\n",
    "SELECT ROLL_NO FROM STUDENT WHERE SECTION='A'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHAR vs VARCHAR in SQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length Handling: CHAR: Fixed length, padded with spaces if shorter. VARCHAR: Variable length, no padding.\n",
    "\n",
    "Storage Size: CHAR: Always uses the defined length. VARCHAR: Uses the actual length of the string plus additional bytes for length information^2^.\n",
    "\n",
    "Performance: CHAR: Generally better performance due to fixed length. VARCHAR: Slightly less performant due to variable length^3^.\n",
    "\n",
    "Use Cases: CHAR: Use when the length of data is consistent (e.g., country codes, fixed-length identifiers). VARCHAR: Use when the length of data varies (e.g., names, descriptions)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
